# GEN-AI-Project

## Retrieval Augmented Extraction using Fine-Tuned LLaMA 3.0

In this project, I developed an AI Agent for Retrieval-Augmented Extraction using a fine-tuned LLaMA 3.0 model, designed to uncover hidden insurance coverage details buried deep within unstructured documents. The challenge was that much of the recovery-related information was not readily available in structured databases, which limited the ability to identify potential claim opportunities. To address this, I implemented a Retrieval-Augmented Generation (RAG) pipeline that significantly enhanced the discovery process, surfacing 25% more recovery signals compared to structured data alone. The pipeline began by converting raw text into vector embeddings using Word2Vec, and then applying a semantic retrieval layer that relied on chunking, LangChain, and cosine similarity to fetch the most relevant context (top-k chunks) for each query. On top of this retrieval framework, I fine-tuned LLaMA 3.0 using LoRA adapters to specialize the model for structured field extraction, ensuring high precision and consistency in identifying critical insurance coverage information. Model validation was carried out by comparing embedding similarity scores between expected and actual outputs, combined with expert feedback review to refine performance. For deployment, I packaged the solution into a Flask API, hosted on Azure Container Apps for scalability and reliability. The deployed system demonstrated strong business impact, driving a 10% increase in recovery success rates and enabling an 18% reduction in claim cycle time, thereby improving both operational efficiency and financial outcomes for insurance claims management.
